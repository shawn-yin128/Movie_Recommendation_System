{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# set up packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"moive analysis\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "location = \"D:/py_movie_recommendation_system/data/\"\n",
    "movies_df = spark.read.load(location+\"movies.csv\", format='csv', header = True)\n",
    "ratings_df = spark.read.load(location+\"ratings.csv\", format='csv', header = True)\n",
    "links_df = spark.read.load(location+\"links.csv\", format='csv', header = True)\n",
    "tags_df = spark.read.load(location+\"tags.csv\", format='csv', header = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# data preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# drop useless column\n",
    "movie_ratings=ratings_df.drop('timestamp')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Data type convert\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "movie_ratings = movie_ratings.withColumn(\"userId\", movie_ratings[\"userId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"movieId\", movie_ratings[\"movieId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"rating\", movie_ratings[\"rating\"].cast(FloatType()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "|     1|    163|   5.0|\n",
      "|     1|    216|   5.0|\n",
      "|     1|    223|   3.0|\n",
      "|     1|    231|   5.0|\n",
      "|     1|    235|   4.0|\n",
      "|     1|    260|   5.0|\n",
      "|     1|    296|   3.0|\n",
      "|     1|    316|   3.0|\n",
      "|     1|    333|   5.0|\n",
      "|     1|    349|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# import package\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "(training,test) = movie_ratings.randomSplit([0.8,0.2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tune model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Create ALS model\n",
    "model_als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\", seed=202112)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Define evaluator as RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Tune model using ParamGridBuilder\n",
    "params = ParamGridBuilder().addGrid(model_als.maxIter, [3, 5, 10]).addGrid(model_als.regParam, [0.1, 0.01, 0.001]).addGrid(model_als.rank, [5, 10, 15]).addGrid(model_als.alpha, [0.1, 0.01, 0.001]).build()\n",
    "\n",
    "# Build Cross validation\n",
    "cv_creator=CrossValidator(estimator=model_als,estimatorParamMaps=params,evaluator=evaluator,numFolds=4,seed=202112)\n",
    "\n",
    "#Fit ALS model to training data\n",
    "cv_model=cv_creator.fit(training)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ALS model parameters by CV:\n",
      "-> maxIter: 10\n",
      "-> regParam: 0.1\n",
      "-> rank: 15\n",
      "-> alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "best_model=cv_model.bestModel\n",
    "best_params=cv_model.getEstimatorParamMaps()[np.argmin(cv_model.avgMetrics)]\n",
    "print('Best ALS model parameters by CV:')\n",
    "for i,j in best_params.items():\n",
    "  print('-> '+i.name+': '+str(j))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model tesing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error for testing data is 0.8842470570103346\n"
     ]
    }
   ],
   "source": [
    "#Generate predictions and evaluate using RMSE\n",
    "prediction_test = best_model.transform(test)\n",
    "rmse_test = evaluator.evaluate(prediction_test)\n",
    "print(\"Root-mean-square error for testing data is \" + str(rmse_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# qualitative check"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.6108675896948604\n"
     ]
    }
   ],
   "source": [
    "# define a function to package the recommendation\n",
    "def topKRecommend(k,id,model):\n",
    "  '''\n",
    "  k: the number of movies to recommend\n",
    "  id: the id of the user to give recommendations\n",
    "  model: the trained model for recommendation\n",
    "  '''\n",
    "  # the table for all top10 recommendations\n",
    "  all_recommd=model.recommendForAllUsers(k)\n",
    "  user_recommd=all_recommd.where(all_recommd.userId==id).toPandas()\n",
    "  if user_recommd.shape[0]==0:\n",
    "    print('No user with id '+str(id)+' is found in the data.')\n",
    "    return None\n",
    "  user_recommd=user_recommd.iloc[0,1]\n",
    "  user_recommd=pd.DataFrame(user_recommd,columns=['movieId','predicted_ratings'])\n",
    "  temp=None\n",
    "  for i in user_recommd['movieId']:\n",
    "    if not temp:\n",
    "      temp=movies_df.where(movies_df.movieId==str(i))\n",
    "    else:\n",
    "      temp=temp.union(movies_df.where(movies_df.movieId==str(i)))\n",
    "  out=pd.concat([temp.toPandas(),user_recommd['predicted_ratings']],axis=1)\n",
    "  out.index=range(1,k+1)\n",
    "  return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = false)\n",
      "\n",
      "+-------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+------------+-------------+----------+\n",
      "|movieId|   feature0|   feature1|   feature2|   feature3|    feature4|    feature5|    feature6|    feature7|   feature8|   feature9|  feature10| feature11|   feature12|    feature13| feature14|\n",
      "+-------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+------------+-------------+----------+\n",
      "|     10| 0.41162598|  0.8771659|  0.5593326| -0.5951011|   0.1903169| -0.39384925| -0.35029674| 0.013529366|  0.5653978| -0.9044589|-0.31923106|0.63338375|  -0.7000344|  -0.19393574| 0.4127357|\n",
      "|     20| 0.52996415|   0.994044|-0.14460136|-0.06842906|   0.6973475| -0.07843322| 0.059889965|  -0.2292617|  0.5264054|  -0.600355|-0.34519655|0.40205365|  -0.5528935|    0.5893246|0.33565205|\n",
      "|     30|  0.6675568| 0.47635356| 0.86876625|-0.12880407| -0.36446324| -0.12835634|  0.32057822| -0.33507252| 0.45903048|-0.57348275| -0.6182366|0.82976216| -0.16997689|   0.42710242| 0.6852607|\n",
      "|     40| 0.48946598| 0.56569815| 0.68033516|-0.20364259| -0.23318982|   0.5003169| -0.44018093| 0.014330218|-0.48455137|-0.72456914|-0.13334793|0.46475914|   0.4025321|  -0.06613642| 0.5238589|\n",
      "|     50| 0.25576147| 0.69693327|  0.8748907| -0.5269715|  0.18737781| -0.20393506| -0.07310803| -0.41524145| 0.83202523|  -1.074152| -1.1460915| 0.9080874| -0.14288944|   0.26661956|0.35864094|\n",
      "|     60| 0.64835227|0.036047116|  0.2631277| -0.7508027| -0.35145274| -0.46970028|  -0.3883831| -0.22494957| 0.45590845|-0.95831823|-0.95316607|0.32717985| -0.12430489|  -0.55347836| 0.5971248|\n",
      "|     70| 0.40824795|  1.0125505| 0.72137165|0.062100843|0.0019024006|  -0.5589761| -0.51471245| -0.43514717| 0.53775823|-0.93969727|-0.43453634|0.72922814| -0.18375134|  -0.20177856| 0.5904189|\n",
      "|     80| 0.49810445| 0.80083144|  0.7089658|-0.33539522| -0.27461004| -0.09416874|  0.08372326|  -0.4265284|  0.9147187| -0.5093495| -0.5151844| 0.8010891| -0.24799013|     0.520205| 0.3955623|\n",
      "|    100| 0.41372123| 0.36747152| 0.28165027| -0.7525446| -0.70767194| -0.48032355|-0.106121525| -0.09159352|  0.6292772|-0.69142526|-0.30627087|0.64744735|-0.058210507|   0.09618687|0.06850263|\n",
      "|    110| 0.46469003|  0.6173121|  0.4255723|  -0.771006|  0.23394965|    -0.15209|  -0.4217871| -0.16259995|   0.990001| -1.2866126|-0.24028885| 0.9441241| -0.38177723|  -0.01906182|0.44092858|\n",
      "|    140| 0.23246714|  0.4780118| 0.32187885| -1.0306941| -0.24030375| -0.13559772|  0.22963977| 0.059208572|  0.9110419|-0.78874665| -0.6276004|0.26458246| -0.19567265| -0.028094469|0.55819124|\n",
      "|    150| 0.19571115| 0.37614688|  0.3050145| -0.6977841| -0.12239915| -0.37487552|  0.07778011| -0.47947955| 0.87837654| -1.3619227| -0.5309544| 0.8588518|  -0.4568192|-0.0033185214|0.11541297|\n",
      "|    160| 0.31684947| 0.56121445| -0.1408708|-0.88664734|  -0.1382046| -0.26590523|  -0.2959773| -0.20216131|  0.5105512|-0.82821816|-0.19768344|0.29617554| -0.69445187|   -0.5698248|0.43422303|\n",
      "|    170|0.067017466|  0.8842568| 0.31292427| -0.6701303| 0.023767833|   -0.656906|-0.123215914|  -0.6389352|  0.8523817|-0.92685324|  -0.078097|0.46689072| -0.14673662|  0.059903298|0.23176393|\n",
      "|    180| 0.46674526|  0.5661465|   1.193409|0.024514746|  0.28558657| -0.39590356| -0.09577225| -0.15580496|   0.854916| -1.0025401|-0.45346963|0.42876452| -0.26995215|   0.29445282|0.52905655|\n",
      "|    190|  1.1167653| 0.44264582|  1.1566042|   0.128312|  -0.5432096|  0.09324001|  0.46226868| -0.45808697|  0.5661539|  0.2304934| 0.09470402| 0.9368867| 0.036966518|    0.8204618|0.43703538|\n",
      "|    210| 0.28026456| 0.40952012| 0.06554353| -0.7462797|0.0065569947| -0.36100447|  0.22171009| -0.39010295| 0.91932493|-0.55749196|-0.29489264|0.43762848|  -0.5139076|   -0.3792254| 0.4293603|\n",
      "|    220|  0.7252035| 0.43680504|  0.1043267| -0.5775001| -0.06380577| -0.36499068|  0.01246573| -0.06401006| 0.13178135| -0.4245362|-0.40875265|0.37191206| -0.19604702|  -0.19228737| 0.2852277|\n",
      "|    230| 0.70289737|  0.5541664|  0.5571702|-0.49346265| -0.48111597|-0.019125255| 0.017945752|-0.052413527|  1.1564957| -0.8366952|-0.21257928| 0.3793718|  -0.7907504|  -0.14546841|0.46052456|\n",
      "|    240|  0.2239168| 0.38396868|-0.06959235| -0.6184232|-0.012219232| -0.62701315|  -0.2865136|  -0.2481207|  0.3625633| -0.5556335|0.005748366|0.31011367|  -0.3386463|  -0.42471215| 0.5291266|\n",
      "+-------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----------+-----------+-----------+----------+------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programming\\python\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# access the movie factor matrix\n",
    "movie_factors=best_model.itemFactors\n",
    "movie_factors.printSchema()\n",
    "comd=[\"movie_factors.selectExpr('id as movieId',\"]\n",
    "for i in range(best_model.rank):\n",
    "  if i<best_model.rank-1:\n",
    "    comd.append(\"'features[\"+str(i)+\"] as feature\"+str(i)+\"',\")\n",
    "  else:\n",
    "    comd.append(\"'features[\"+str(i)+\"] as feature\"+str(i)+\"'\")\n",
    "comd.append(')')\n",
    "movie_factors=eval(''.join(comd))\n",
    "movie_factors.createOrReplaceTempView('movie_factors')\n",
    "movie_factors.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "# the larger the cosine value, the smaller the two feature vectors' angle, the similar the movies\n",
    "# this similarity considers the direction only,\n",
    "# e.g. movie 1 with factor [1,2,3] and movie 2 with factor [2,4,6] are considered the same\n",
    "def cos_similar(k,mid):\n",
    "  '''\n",
    "  k: number of similar movies to find\n",
    "  mid: id of the movie to find similarities\n",
    "  '''\n",
    "  movie_info=spark.sql('select * from movie_factors where movieId='+str(mid)).toPandas()\n",
    "  if movie_info.shape[0]<=0:\n",
    "    print('No movie with id '+str(mid)+' is found in the data.')\n",
    "    return None, None\n",
    "  norm_m=sum(movie_info.iloc[0,1:].values**2)**0.5\n",
    "  temp=['select movieId,']\n",
    "  norm_str=['sqrt(']\n",
    "  for i in range(best_model.rank):\n",
    "    comd='feature'+str(i)+'*'+str(movie_info.iloc[0,i+1])\n",
    "    temp.append(comd+' as inner'+str(i)+',')\n",
    "    if i<best_model.rank-1:\n",
    "      norm_str.append('feature'+str(i)+'*feature'+str(i)+'+')\n",
    "    else:\n",
    "      norm_str.append('feature'+str(i)+'*feature'+str(i))\n",
    "  norm_str.append(') as norm')\n",
    "  temp.append(''.join(norm_str))\n",
    "  temp.append(' from movie_factors where movieId!='+str(mid))\n",
    "  inner=spark.sql(' '.join(temp))\n",
    "  inner=inner.selectExpr('movieId',\\\n",
    "                         '(inner0+inner1+inner2+inner3+inner4)/norm/'+str(norm_m)+' as innerP').\\\n",
    "                         orderBy('innerP',ascending=False).limit(k).toPandas()\n",
    "  out=None\n",
    "  for i in inner['movieId']:\n",
    "    if not out:\n",
    "      out=movies_df.where(movies_df.movieId==str(i))\n",
    "    else:\n",
    "      out=out.union(movies_df.where(movies_df.movieId==str(i)))\n",
    "  out=out.toPandas()\n",
    "  out.index=range(1,k+1)\n",
    "  return out, inner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}